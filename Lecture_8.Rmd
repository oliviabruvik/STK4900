---
title: "STK4900 - Statistical Methods and Applications"
author: "Olivia Beyer Bruvik"
date: "6/13/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lecture 8  {.tabset}

```{r, include = FALSE}
cigarettes=read.table("https://www.uio.no/studier/emner/matnat/math/STK4900/data/sigarett.txt", header=T)
```

## Topics
1. Poisson distribution (3)
1. Poisson regression (14)
1. Generalized linear models (24)

<https://www.uio.no/studier/emner/matnat/math/STK4900/v21/lectures/lecture8.pdf>

```{r, include = FALSE}
car.claims=read.table("http://www.uio.no/studier/emner/matnat/math/STK4900/data/car-claims.txt", header=T)
```

## Poisson distribution
### The Poisson distribution
An appropriate model for "rare events" that are happening "randomly over time/space"

Arises as:

* an approximation to the distribution of $Y \sim \binom {n}{p}$ when *p* is small and *n* is large ($\lambda = np$)
* from a Poisson process

$$
P(Y=y) = \frac{\lambda^y}{y!} e^{-\lambda}, \quad y = 0,1,2,... \\
Y \sim Po(\lambda) \\
E(Y) = Var(Y) = \lambda
$$

### Poisson approximation to the binomial distribution

$$
\binom{n}{p} p^y (1-p)^{n-y} \approx \frac{\lambda^y}{y!} e^{-\lambda}
$$

### Poisson process {.tabset}

#### Time

Let Y be the number of events in an interval of length t:

$$
Y \sim Po(\lambda t)
$$

##### Assumptions
1. the rate of events \lambda is constant over time (rate = expected number of events per unit of time)
1. the number of events in disjoint time-intervals are independent
1. events do not occur together


#### Space

Let Y be the number of events in an area of size a:

$$
Y \sim Po(\lambda a)
$$

##### Assumptions
1. the rate of points \lambda is constant over the region (rate = expected number of points in an area of size 0)
1. the number of events in disjoint areas are independent
1.points do not coincide

### Overdispersion
The expected value and variances are both estimates of \lambda and therefore approximately equal:

$$
\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \\
s^2 = \frac{1}{n-1} \sum_{i=1}^n (y_i - \bar{y})^2
$$


#### Coefficient of dispersion

$$
CD = \frac{s^2}{\bar{y}} \\
CD >> 1 \rightarrow overdispersion
$$

#### Overdispersion term
Should be close to 1 if the Poisson model is correct
$$
\begin{align}
\phi &= \frac{1}{n-p} \sum_{i=1}^n \frac{(Y_i - \hat{\mu}_i)^2}{\hat{\mu_i}} \\
&= \frac{X^2}{n}
\end{align}
$$

#### Correction for overdispersion
We can allow for overdispersion by specifying a model $Var(Y_i) = \phi V (\mu_i)$, where $V (\mu)$ is the variance function (see notes on GLMs). 

Overdispersed Poission model given by:

$$
\begin{align}
log(\mu_i) &= \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + ... + \beta_px_{pi} \\
Var(Y_i) &= \phi \mu_i
\end{align}
$$

Correction of standard errors: $se* = se \sqrt{\hat{\phi}}$
Correction of z-values: $z* = \frac{z}{\sqrt{\hat{\phi}}}$

#### Implementation in R (quasi-likelihood)

```{r, eval = FALSE}
glm(
  partners~Gender+Married+factor(HIVtest)+factor(agegr),
  family=quasi(link=log,
               var="mu"),
  data=part)
```

### Test of Poisson distribution

Data: $y_1, y_2, ..., y_n$
Null: $H_0: $ data are Poisson distributed

1. Estimate (MLE): $\hat{\lambda} = \bar{y}$
1. Compute expected frequencies under $H_0: E_j = n \times \frac{\hat{\lambda}^j}{j!} e^{-\hat{\lambda}}
1. Compute observed frequencies: $O_j = n(y_i) \text{ equal to j}
1. Aggregate (K) groups with small expected numbers, so that all $E_j's \geq 5$.
1. Compute Pearson chi-square statistic:

$$ X^2 = \sum{\frac{(O_j - E_j)^2}{E_j}} \sim K-2 $$

If $p > 0.25$, the Poisson distribution fits nicely to the data.

## Poisson regression

$$
\begin{align}
\lambda_{i} &= \lambda(x_{1i}, x_{2i}, ..., x_{pi}) \\
&= e^{\beta_0 + \beta_1x_{1i} + \beta_2x_{2i}+...+\beta_px_{pi}}
\end{align}
$$

### Data
$$
y_i, x_{1i}, x_{2i},...,x_{pi} \quad i=1,...,n \\
\begin{align}
y_i &= \text{a count for subject } i \\
x_{ji} &= \text{predictor (covariate) j for subject i}
\end{align}
$$

### Assumptions
* responses $y_i$ are realizations of independent Poisson distributed random variables $Y_i \sim Po(\lambda_i)$
* $\lambda_i = \lambda(x_{1i}, x_{2i}, ..., x_{pi})$ is a function of the covariates


### Rate ratio (RR)
$e^{\beta_1 \Delta}$ is the rate ratio corresponding to one unit's increase in the value of the first covariate *holding all other covariates constant*

$$
\begin{align}
RR &= \frac{\lambda(x_1 + \Delta, x_2, ..., x_p)}{\lambda(x_1, x_2, ..., x_p)} \\
&= \frac{
exp(\beta_0 + \beta_1(x_{1} + \Delta) + \beta_2x_{2}+...+\beta_px_{p})}
{exp(\beta_0 + \beta_1x_{1} + \beta_2x_{2}+...+\beta_px_{p})} \\
&= e^{\beta_1 \Delta}
\end{align}
$$

### Aggregated counts (grouped)
An observation *y~i~* is a realization of $Y_i \sim Po(w_i \lambda_i)$ where the weight *w~i~* is the number of subjects in group ~i~. 


$$
\begin{align}
E(Y_i) &= w_i \lambda_i \\
&= w_i exp(\beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + ... + \beta_px_{pi}) \\
&= exp(log(w_i) + \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + ... + \beta_px_{pi})
\end{align} \\
log(w_i) \text{ is an offset: a covariate where the regression coefficient is known to equal 1}
$$

```{r, results = 'hide'}
fit.claims=glm(
  acc~offset(log(num))+factor(age)+factor(vol),
  data=car.claims,
  family=poisson)

summary(fit.claims)
```

### Interpretation

* $e^{\hat{\beta_0}} = e^{-1.916} = 0.147$ is the expected number of claims for a driver with age < 30y with a small car. 
* $e^{\hat{\beta_1}} = e^{-0.376} = 0.687$ is the rate ratio for a driver aged $\geq$ 30y *compared with a driver younger than 30 years (with same car type)*.

### Maximum likelihood estimation

$$ 
P(Y_i = y_i) = \frac{(w_i \lambda_i)^{y_i}}{y_i!} exp(-w_i \lambda_i) \\
$$

#### Likelihood

$$
\text{Likelihood is the simultaneous distribution: }\\
L = \prod_{i=1}^n \frac{(w_i \lambda_i)^{y_i}}{y_i!} exp(-w_i \lambda_i) \\
\text{considered as a function of the parameters } \beta_0, \beta_1, ..., \beta_p \text{ for the observed values of the } y_i \\
$$

#### Maximum likelihood estimates (MLE)

$$
\hat{\beta_0}, \hat{\beta_1}, ..., \hat{\beta_p} \rightarrow max(L) = max(l = log(L))
$$

### Wald tests and confidence intervals

$$
\begin{align}
\hat{\beta_j} &= MLE \space for \space \beta_j \\
se(\hat{\beta_j}) &= standard \space error \space for \hat{\beta_j} \\
\end{align}
$$
#### Wald test statistic

$$
\begin{align}
H_{0j} &: \beta_j = 0 \\
z &= \frac{\hat{\beta_j}}{se(\hat{\beta_j})} \sim N(0,1)
\end{align}
$$

#### 95% confidence interval

$$
\hat{\beta_j} \pm 1.96 \times se(\hat{\beta_j}) \\
e^{\hat{\beta_j} \pm 1.96 \times se(\hat{\beta_j})} \leq RR \leq e^{\hat{\beta_j} \pm 1.96 \times se(\hat{\beta_j})}
$$

```{r}
## Rate ratios with CI
expcoef <- function(glmobj) {
  regtab=summary(glmobj)$coef
  expcoef=exp(regtab[,1])
  lower=expcoef*exp(-1.96*regtab[,2])
  upper=expcoef*exp(1.96*regtab[,2])
  cbind(expcoef,lower,upper)
}

expcoef(fit.claims)
```

### Deviance and likelihood ratio tests

$H_0: q$  of the $B_j's = 0$, or equivalently, <br>
$H_0:$ there are *q* linear restrictions among the $B_j's$

#### Log likelihoods
$$ 
\begin{align}
l &= \text{the maximum possible value of the log-likelihood, obtained for the saturated model with no restriction on the } \lambda_i \\
\hat{l} &= log \hat{L} \text{ is the log-likelihood for the full Poisson regression model} \\
\hat{l_0} &= log \hat{L_0} \text{ is the log-likelihood under } H_0 \\
\end{align}
$$

Deviance and test statistic

$$
\begin{align}
D &= 2(l-\hat{l}) \quad and \quad D_0 = 2(l-\hat{l}_0) \\
G &= D_0 - D \sim X^2, \space q \space df\\
&= -2 log (\frac{\hat{L_0}}{\hat{L}})
\end{align}
$$

```{r, results = 'hide'}
fit.null=glm(
  acc~offset(log(num)),
  data=car.claims,
  family=poisson)

fit.age=glm(
  acc~offset(log(num))+factor(age), 
  data=car.claims,
  family=poisson)

fit.age.vol=glm(
  acc~offset(log(num))+factor(age)+factor(vol), 
  data=car.claims,
  family=poisson)

fit.interaction=glm(
  acc~offset(log(num))+factor(age)+factor(vol) +factor(age):factor(vol),
  data=car.claims,family=poisson)

anova(fit.null,
      fit.age,
      fit.age.vol,
      fit.interaction,
      test="Chisq")
```

#### Interpretation
We end up with model 3 with no interaction

## Generalized linear models (GLMs)

### Common GLMs:

1. Multiple linear regression
1. Logistic regression
1. Poisson regression

### Parts of GLMs:

A family of distributions

* Poisson: observations Y~i~ are independent and Poisson distributed with means $\mu_i = E(Y_i)$
* MLR: normal
  
A linear predictor

* Poisson: a linear expression in regression and covariates, $\eta_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + ... + \beta_px_{pi}$
* MLR: 
  
A link function

* Poisson: $\eta_i = g(\mu_i) = log(\mu_i)$
* MLR: $\eta_i = g(\mu_i) = log(\mu_i)$
* Logistic: $\eta_i = g(\mu_i) = log(\frac{\mu_i}{1-\mu_i})

NB. Other link functions may be specified (slide 26).

### Statistical inference

Estimation: maximum likelihood (MLE)
Testing:

1. Wald tests
1. Deviance / likelihood ratio tests

### Variance function
Describe how the variance depends on the mean \mu. <br>
Specific for each family of distributions.

$$
Poisson: V(\mu) = \mu \\
Binary \space data: V(\mu) = \mu(1 - \mu) \\
Normal \space data: V(\mu) = 1 \\
$$

$V(\mu) = 1$ for normal data because the variance doesn't depend on the mean, thus $Var(Y_i) = \sigma^2 = \sigma ^ 2 V (\mu_i)$.

### Heteroscedastic linear model

Assume:

1. an acceptable linear structure, $E(Y_i) = \mu_i = \beta_0 + \beta_1x){1i} + \beta_2x_{2i} + ... + \beta_px_{pi}$
1. a non-constant variance that depended on $\mu_i$, $Var(Y_i) \approx \phi\mu_i$

Solution: specify a quasi-likelihood model with identitiy link and variance function $\mu$ in R. 

## Generalized additive models (GAM)
An extension of GLMs.

### Parts of GAMs

1. A family of distributions
1. A link function
1. An additive predictor, $\eta_i = \beta_0 + f_1(x_{1i}) + f_2(x_{2i}) + ... + f_p(x_{pi})$

Use the GAM library (R examples lecture 5, slide 19 and lecture 7, slide 35).


